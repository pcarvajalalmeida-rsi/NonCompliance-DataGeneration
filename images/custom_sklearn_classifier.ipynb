{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60640a31-a2ad-4d5d-9f90-d7d76ea5679b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, precision_score, \n",
    "    recall_score, log_loss, roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48eeaac9-28e0-4156-843e-902a11f4eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleOutputModel(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self,*model_list): # no *args or **kargs\n",
    "        ''' \n",
    "            Args:\n",
    "                *modellist: list of (name, pred_type, model) tuples\n",
    "\n",
    "                \"name\" is full description, \"pred_type\" is 'isCalc' or 'isPII' (e.g.)\n",
    "                \n",
    "                The only real methods that need to be defined are:\n",
    "                    __init__, fit, predict \n",
    "                optional but very useful: predict_proba\n",
    "                \n",
    "        '''\n",
    "\n",
    "        self.names   = [nm[0] for nm in model_list]\n",
    "        self.model_tag = [nm[1] for nm in model_list]\n",
    "        self.models  = [nm[2] for nm in model_list]\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ': ' + str([(n,m) for n, m in zip(self.names,self.models)])\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key,int):\n",
    "            return self.models[key]\n",
    "        elif key in self.model_tag:\n",
    "            return self.models[self.model_tag.index(key)]\n",
    "        else:\n",
    "            raise KeyError(f'bad key: {key}')\n",
    "\n",
    "    def __keys__(self):\n",
    "        for tag in self.models:\n",
    "            yield tag\n",
    "\n",
    "    def __items__(self):\n",
    "        for tag, model in zip(self.model_tag, self.models):\n",
    "            yield tag, model\n",
    "\n",
    "    def items(self):\n",
    "        return [(tag, model) for tag, model in zip(self.model_tag, self.models)]\n",
    "\n",
    "    @property\n",
    "    def tags(self):\n",
    "        return [pt for pt in self.model_tag]\n",
    "    \n",
    "    @property\n",
    "    def _estimator_type(self):\n",
    "        if all(getattr(estimator, \"_estimator_type\", None) == \"classifier\" \n",
    "                for estimator in self.models):\n",
    "            return \"classifier\"\n",
    "        elif all(getattr(estimator, \"_estimator_type\", None) == \"regressor\" \n",
    "                for estimator in self.models):\n",
    "            return \"regressor\"\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def add_model(self,name_tag_model):\n",
    "        self.names.append(name_tag_model[0])\n",
    "        self.model_tag.append(name_tag_model[1])\n",
    "        self.models.append(name_tag_model[2])\n",
    "        \n",
    "    def add_models(self,name_tag_model_list):\n",
    "        self.names.extend([nm[0] for nm in name_tag_model_list])\n",
    "        self.model_tag.extend([nm[1] for nm in name_tag_model_list])\n",
    "        self.models.extend([nm[2] for nm in name_tag_model_list])\n",
    "    \n",
    "    def fit(self, X, ylist, **kwargs):\n",
    "        if isinstance(X,dict):\n",
    "            assert len(ylist) == len(X), 'input data set and labels mismatched sizes'\n",
    "            if isinstance(ylist,list):\n",
    "                ylist = {k: ylist[i] for i,k in enumerate(X.keys())}\n",
    "            data_keys = set(X.keys())\n",
    "            model_keys = set(self.model_tag)\n",
    "            assert len(data_keys.symmetric_difference(model_keys)) == 0, (\n",
    "                'data and models do not share the same tags')\n",
    "            return {pt: model.fit(X[pt], ylist[pt],**kwargs) \n",
    "                    for pt, model in zip(self.model_tag,self.models)}\n",
    "        else:\n",
    "            assert len(ylist) == len(self.models), (\n",
    "                'number of models mismatched to the number of label sets')\n",
    "            return {pt: model.fit(X,y,**kwargs) \n",
    "                    for pt, model, y in zip(self.model_tag,self.models,ylist)}\n",
    "\n",
    "    def predict_proba(self, X, with_tag=True, **kwargs):\n",
    "        ''' predict_proba\n",
    "\n",
    "            the 1 - prob(class=0) is used to identify the probability of the class of interest\n",
    "        '''\n",
    "        if with_tag:\n",
    "            if isinstance(X,dict):\n",
    "                data_keys = set(X.keys())\n",
    "                model_keys = set(self.model_tag)\n",
    "                assert len(data_keys.symmetric_difference(model_keys)) == 0, (\n",
    "                    'data and models do not share the same tags')\n",
    "                return {pt: 1-model.predict_proba(X[pt],**kwargs)[:,0] \n",
    "                        for pt, model in zip(self.model_tag,self.models)}\n",
    "            else:\n",
    "                return {pt: 1-model.predict_proba(X,**kwargs)[:,0] \n",
    "                        for pt, model in zip(self.model_tag,self.models)}\n",
    "        else:\n",
    "            if isinstance(X,list) and len(X) == len(self.models):\n",
    "                return [1-model.predict_proba(Xsub,**kwargs)[:,0] for model, Xsub in zip(self.models, X)]\n",
    "            else:\n",
    "                return [1-model.predict_proba(X,**kwargs)[:,0] for model in self.models]\n",
    "\n",
    "    def predict(self, X, with_tag=True, **kwargs):\n",
    "        if with_tag:\n",
    "            if isinstance(X,dict):\n",
    "                data_keys = set(X.keys())\n",
    "                model_keys = set(self.model_tag)\n",
    "                assert len(data_keys.symmetric_difference(model_keys)) == 0, (\n",
    "                    'data and models do not share the same tags')\n",
    "                return {pt: model.predict(X[pt],**kwargs) \n",
    "                        for pt, model in zip(self.model_tag,self.models)}\n",
    "            else:\n",
    "                return {pt: model.predict(X,**kwargs) \n",
    "                        for pt, model in zip(self.model_tag,self.models)}\n",
    "        else:\n",
    "            if isinstance(X,list) and len(X) == len(self.models):\n",
    "                return [model.predict(Xsub,**kwargs) for model, Xsub in zip(self.models, X)]\n",
    "            else:\n",
    "                return [model.predict(X,**kwargs) for model in self.models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87a938c1-ece6-4c12-a34c-ea24d1b3b0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Section', 'Field', 'FieldText', 'isCalc', 'isPII', 'isCode',\n",
       "       'isCheckbox', 'isMultipleChoice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../AnalyticsNLP/formsML/tests/test_data/form_data.train.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f361d7d-b90c-4e2d-bd28-b3222ed606d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                             FieldText\n",
       " 119            What type of entity is this shareholder\n",
       " 134  Combination of Kentucky Schedule K-1, 1-5,8 an...\n",
       " 51                             Prior year's tax credit\n",
       " 32                        LLET paid on original return\n",
       " 88                              Alternative allocation,\n",
       "      label\n",
       " 119      0\n",
       " 134      0\n",
       " 51       0\n",
       " 32       0\n",
       " 88       0,\n",
       "                                FieldText\n",
       " 141                          Rents/Lease\n",
       " 27   Certified rehabilitation tax credit\n",
       " 29                     Extension payment\n",
       " 97                        Total payrolls\n",
       " 123              Kentucky gross receipts,\n",
       "      label\n",
       " 141      0\n",
       " 27       0\n",
       " 29       0\n",
       " 97       0\n",
       " 123      0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(seed=42)\n",
    "labels = pd.DataFrame(dict(label=2*df['isPII'].values+df['isCalc'].values))\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df[['FieldText']],\n",
    "            labels,\n",
    "            test_size=0.2,\n",
    "            stratify=labels, \n",
    "            random_state=rng)\n",
    "\n",
    "train_labels = [(y_train == lbl).values  for k, lbl in zip(['isPII', 'isCalc'],[1,2])]\n",
    "test_labels = [(y_test == lbl).values  for k, lbl in zip(['isPII', 'isCalc'],[1,2])]\n",
    "# pd.concat([X_train, y_train],axis=1,ignore_index=True).head(), pd.concat([X_test, y_test],axis=1,ignore_index=True).head()\n",
    "X_train.head(), y_train.head(), X_test.head(), y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "054f0d6b-93fa-49bf-a404-58d2f1c02a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['PII classifier', 'calculated field classifier']\n",
    "tag_list = ['pii', 'icCalc']\n",
    "cols2select = ['FieldText']\n",
    "\n",
    "# Fit the CountVectorizer to the training data\n",
    "preproc = CountVectorizer().fit(df['FieldText'])\n",
    "\n",
    "\n",
    "models = [Pipeline([\n",
    "         (\"selector\", ColumnTransformer([(\"selector\", \"passthrough\", cols2select)], remainder=\"drop\")),\n",
    "         ('ravel', FunctionTransformer(np.ravel, check_inverse=False)),\n",
    "         ('preproc', preproc),\n",
    "         ('model', LogisticRegression(C=20))\n",
    "        ]) for n in names]\n",
    "\n",
    "mm = MultipleOutputModel(*[(n,t,m) for n,t,m in zip(names, tag_list, models)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b4cbc58-09c4-42f1-b010-80e9196f505c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nick/anaconda3/envs/core/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/nick/anaconda3/envs/core/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pii': Pipeline(steps=[('selector',\n",
       "                  ColumnTransformer(transformers=[('selector', 'passthrough',\n",
       "                                                   ['FieldText'])])),\n",
       "                 ('ravel',\n",
       "                  FunctionTransformer(check_inverse=False,\n",
       "                                      func=<function ravel at 0x7f053c3251f0>)),\n",
       "                 ('preproc', CountVectorizer()),\n",
       "                 ('model', LogisticRegression(C=20))]),\n",
       " 'icCalc': Pipeline(steps=[('selector',\n",
       "                  ColumnTransformer(transformers=[('selector', 'passthrough',\n",
       "                                                   ['FieldText'])])),\n",
       "                 ('ravel',\n",
       "                  FunctionTransformer(check_inverse=False,\n",
       "                                      func=<function ravel at 0x7f053c3251f0>)),\n",
       "                 ('preproc', CountVectorizer()),\n",
       "                 ('model', LogisticRegression(C=20))])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a0feaa5-9a77-4764-bdb6-51c8e897ee06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_pii_recall_score</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_pii_precision_score</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_pii_log_loss</th>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_pii_accuracy_score</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_icCalc_recall_score</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_icCalc_precision_score</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_icCalc_log_loss</th>\n",
       "      <td>9.992007e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_icCalc_accuracy_score</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_pii_recall_score</th>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_pii_precision_score</th>\n",
       "      <td>3.750000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_pii_log_loss</th>\n",
       "      <td>7.894692e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_pii_accuracy_score</th>\n",
       "      <td>7.714286e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_icCalc_recall_score</th>\n",
       "      <td>6.666667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_icCalc_precision_score</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_icCalc_log_loss</th>\n",
       "      <td>9.868222e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_icCalc_accuracy_score</th>\n",
       "      <td>9.714286e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         0\n",
       "train_pii_recall_score        1.000000e+00\n",
       "train_pii_precision_score     1.000000e+00\n",
       "train_pii_log_loss            9.992007e-16\n",
       "train_pii_accuracy_score      1.000000e+00\n",
       "train_icCalc_recall_score     1.000000e+00\n",
       "train_icCalc_precision_score  1.000000e+00\n",
       "train_icCalc_log_loss         9.992007e-16\n",
       "train_icCalc_accuracy_score   1.000000e+00\n",
       "test_pii_recall_score         5.000000e-01\n",
       "test_pii_precision_score      3.750000e-01\n",
       "test_pii_log_loss             7.894692e+00\n",
       "test_pii_accuracy_score       7.714286e-01\n",
       "test_icCalc_recall_score      6.666667e-01\n",
       "test_icCalc_precision_score   1.000000e+00\n",
       "test_icCalc_log_loss          9.868222e-01\n",
       "test_icCalc_accuracy_score    9.714286e-01"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = (roc_auc_score, accuracy_score, precision_score, \n",
    "    recall_score, log_loss, roc_curve)\n",
    "\n",
    "pred_trn = mm.predict(X_train)\n",
    "\n",
    "pred_tst = mm.predict(X_test)\n",
    "\n",
    "met = pd.DataFrame()\n",
    "for f in metrics:\n",
    "    for (tag,prd), lbl in zip(pred_trn.items(), train_labels):\n",
    "        met['_'.join(['train', tag, f.__name__])] = [f(prd,lbl)]\n",
    "    for (tag,prd), lbl in zip(pred_tst.items(), test_labels):\n",
    "        met['_'.join(['test', tag, f.__name__])] = [f(prd,lbl)]\n",
    "met[list(reversed(sorted([m for m in met.columns if 'roc' not in m])))].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116555a6-2379-40d8-bfeb-f23d949caf36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
